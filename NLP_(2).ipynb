{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#pip install stanfordnlp"
      ],
      "metadata": {
        "id": "01YAwdH73ZzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "import nltk\n",
        "nltk.download('large_grammars')"
      ],
      "metadata": {
        "id": "Hmozhw1Q6B2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "sentence = \"john lives in new york city, which is the biggest city in united states\"\n",
        "doc = nlp(sentence)\n",
        "for token in doc:\n",
        "    relations = []\n",
        "    for child in token.children:\n",
        "        relations.append((token.text, child.text, child.dep_))\n",
        "    for relation in relations:\n",
        "        print(relation[1], relation[0], relation[2])\n",
        "        \n",
        "  "
      ],
      "metadata": {
        "id": "4XIVzVl4-jaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the English language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Define the sentence to parse\n",
        "sentence = \"John loves Mary.\"\n",
        "\n",
        "# Parse the sentence using Spacy's dependency parser\n",
        "doc = nlp(sentence)\n",
        "\n",
        "# Print the dependencies for each token in the sentence\n",
        "for token in doc:\n",
        "    print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
        "          [child for child in token.children])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "i_8MzLRyBTCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install textrazor"
      ],
      "metadata": {
        "id": "8sfvYyDiDNGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from nltk import Tree\n",
        "\n",
        "\n",
        "en_nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "doc = en_nlp(\"John lives in Delhi, which is the biggest city in India\")\n",
        "\n",
        "def to_nltk_tree(node):\n",
        "    if node.n_lefts + node.n_rights > 0:\n",
        "        return Tree(node.orth_, [to_nltk_tree(child) for child in node.children])\n",
        "    else:\n",
        "        return node.orth_\n",
        "\n",
        "\n",
        "[to_nltk_tree(sent.root).pretty_print() for sent in doc.sents]\n"
      ],
      "metadata": {
        "id": "BGDH6mg0FIU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# load the English language model in spaCy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# define the sentence to be parsed\n",
        "sentence = \"John works at a company called Acme\"\n",
        "\n",
        "# parse the sentence using spaCy\n",
        "doc = nlp(sentence)\n",
        "\n",
        "# extract entities and relationships from the parse\n",
        "entities = [ent.text for ent in doc.ents if ent.label_ == 'PERSON']\n",
        "relationships = []\n",
        "for token in doc:\n",
        "    if token.dep_ == 'nsubj':\n",
        "        relationships.append((token.lemma_, token.head.lemma_))\n",
        "    elif token.dep_ == 'dobj':\n",
        "        relationships.append((token.head.lemma_, token.lemma_))\n",
        "\n",
        "# print the entities and relationships\n",
        "print(\"Entities:\", entities)\n",
        "print(\"Relationships:\", relationships)\n"
      ],
      "metadata": {
        "id": "4bWcDH8L02Jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the entities and relationships\n",
        "entities = [\"John\", \"company\", \"Acme\"]\n",
        "relationships = [(\"John\", \"company\", {\"label\": \"works at\"}), (\"company\", \"Acme\", {\"label\": \"called\"})]\n",
        "\n",
        "# Create a directed graph\n",
        "G = nx.DiGraph()\n",
        "\n",
        "# Add the nodes and edges to the graph\n",
        "G.add_nodes_from(entities)\n",
        "G.add_edges_from(relationships)\n",
        "\n",
        "# Draw the graph\n",
        "pos = nx.spring_layout(G)\n",
        "nx.draw_networkx_nodes(G, pos)\n",
        "nx.draw_networkx_edges(G, pos)\n",
        "nx.draw_networkx_labels(G, pos)\n",
        "nx.draw_networkx_edge_labels(G, pos, edge_labels={(u, v): d[\"label\"] for u, v, d in G.edges(data=True)})\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DuPkYBhq0JrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"John works at a company called Acme\")\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
      ],
      "metadata": {
        "id": "QeTiGlar5VcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "nlp=spacy.load('en_core_web_sm')\n",
        "displacy.render(doc,jupyter=True)"
      ],
      "metadata": {
        "id": "2Nhcop6H7l6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"john works at a company named acme\")\n",
        "span = doc[doc[4].left_edge.i : doc[4].right_edge.i+1]\n",
        "with doc.retokenize() as retokenizer:\n",
        "    retokenizer.merge(span)\n",
        "for token in doc:\n",
        "    print(token.text, token.pos_, token.dep_, token.head.text)"
      ],
      "metadata": {
        "id": "zx19ci33Sf1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Sample sentence\n",
        "text = \"John works at Google in California.\"\n",
        "\n",
        "# Apply SpaCy pipeline\n",
        "doc = nlp(text)\n",
        "\n",
        "# Extract entities\n",
        "entities = [(entity.text, entity.label_) for entity in doc.ents]\n",
        "\n",
        "# Extract relations\n",
        "relations = []\n",
        "for token in doc:\n",
        "    if token.dep_ == \"nsubj\":\n",
        "        subject = token.text\n",
        "        for child in token.children:\n",
        "            if child.dep_ == \"prep\" and child.text == \"at\":\n",
        "                for grandchild in child.children:\n",
        "                    if grandchild.dep_ == \"pobj\":\n",
        "                        object = grandchild.text\n",
        "                        relations.append((subject, \"works at\", object))\n",
        "\n",
        "# Display dependency tree\n",
        "spacy.displacy.render(doc, style=\"dep\", jupyter=True)\n",
        "\n",
        "print(\"Entities:\", entities)\n",
        "print(\"Relations:\", relations)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Az3FuguDn_06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JHi2DruHnwLh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}